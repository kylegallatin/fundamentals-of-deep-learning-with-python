{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: Deep Learning for Computer Vision\n",
    "\n",
    "Computer vision is a subfield of artificial intelligence (AI) that focuses on enabling machines to interpret and make decisions based on visual data, i.e., images or videos. Think of it as teaching machines to \"see\" and understand the content of digital images like humans do. Its applications are vast and varied and include:\n",
    "\n",
    "- Facial Recognition: Used in security systems, smartphones, and social media applications.\n",
    "- Medical Imaging: Assisting doctors in detecting anomalies like tumors in MRI scans.\n",
    "- Autonomous Vehicles: Enabling cars to navigate on roads by detecting other cars, pedestrians, and obstacles.\n",
    "- Augmented Reality (AR) and Virtual Reality (VR): Overlaying digital content on the real world or creating immersive virtual worlds.\n",
    "- Object Detection: Identifying objects within images or real-time video streams.\n",
    "\n",
    "Given the richness and complexity of visual data, traditional programming approaches, where explicit rules for every possible scenario are written, become infeasible. Instead, machine learning, especially deep learning, has proven highly effective in extracting patterns and understanding content from visual data.\n",
    "\n",
    "## Goals of this notebook\n",
    "\n",
    "- become comfortable working with images in Python\n",
    "- build and train a convolutional neural network in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with images in Python\n",
    "\n",
    "We can load images into iPython and visualize them using the `PIL` library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load a color image using PIL\n",
    "img = Image.open(\"path_to_image.jpg\")\n",
    "\n",
    "# Display the color image using matplotlib\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # To hide the axis values\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this snippet is helpful for viewing the image, we discussed color images as 3-dimensional metrics! Let's take a look how this image looks when converted to a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to a PyTorch tensor\n",
    "transform = transforms.ToTensor()\n",
    "img_tensor = transform(img)\n",
    "\n",
    "# Print out the tensor shape to verify\n",
    "# For a color image, it should have 3 channels (C x H x W format)\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing a Convolutional Neural Network in PyTorch\n",
    "\n",
    "Just like designing simple neural networks with fully connected layers, we can use PyTorch's `nn` module to create convolutional and pooling layers.\n",
    "\n",
    "Let's design a neural network with:\n",
    "- 1 convolutional layer\n",
    "- 1 pooling layer\n",
    "- 2 fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(32 * 14 * 14, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 32 * 14 * 14)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparaing image data for a convolutional neural network with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations (convert to tensor and normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download the Fashion MNIST dataset\n",
    "train_dataset = datasets.FashionMNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.FashionMNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, targets in test_loader:\n",
    "        outputs = model(data)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on the test images: {100 * correct / total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
