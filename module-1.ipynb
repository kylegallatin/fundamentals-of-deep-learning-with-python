{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 - Introduction to tensors with PyTorch\n",
    "\n",
    "Fundamentally, deep learning is applied mathematics. While some of the math is fairly complex and verbose, the basic building block that enables programmatic deep learning in libraries like PyTorch is the _tensor_. \n",
    "\n",
    "Tensors are single or multi-dimensional matrices on which we perform the mathematical operations that make deep learning possible. To create a tensor, we can use PyTorch's `torch.tensor` method.\n",
    "\n",
    "The purpose of this notebook is to get you familiar working with `torch.Tensor` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and inspecting tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.tensor([0])\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in the example above, we created a tensor from a Python list that had 1 element. To create tensors with more dimensions, we can use lists with more elements or nested lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_element_tensor = torch.tensor([0,1,2])\n",
    "multidim_tensor = torch.tensor([[0,1],[2,3],[4,5]])\n",
    "\n",
    "print(f\"Tensor with 3 elements:\\n {three_element_tensor}\")\n",
    "print(f\"Tensor with more than 1 dimension:\\n {multidim_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `shape` method to inspect the shape of our tensor at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multidim_tensor.shape)\n",
    "print(three_element_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch tensors and NumPy arrays\n",
    "\n",
    "If you've used matrices and arrays in Python before, you might notice these look very similar to _NumPy arrays_. NumPy is a very popular library for working with matrices and arrays in Python, and provides the building blocks for data manipulation libraries such as Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "array = np.array([0])\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, PyTorch even provides methods to create tensors directly from NumPy arrays - and even allows them to share the same memory location!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_from_numpy = torch.from_numpy(array)\n",
    "\n",
    "print(tensor_from_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo! Of course, right around now you might be wondering, _what's the difference? Why do we even need PyTorch_? \n",
    "\n",
    "Great questions honestly. And there are a couple of key differentiators:\n",
    "\n",
    "1. PyTorch provides additional APIs and and higher-level methodologies for working with tensors that are helpful to deep learning \n",
    "2. PyTorch has a system called _automatic differentiation_ which helps automate and abstract away the key mathematical operations that allow deep learning models to learn\n",
    "3. PyTorch includes hardware-specific operations for accelerating deep learnining model training on GPUs\n",
    "\n",
    "These make PyTorch a go-to library for those working in the machine learning space. Other than that, it will look very similar to other NumPy APIs for creating arrays and various shapes and sizes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = torch.zeros(3, 2)  # Create a tensor filled with zeros of size 3x2\n",
    "ones = torch.ones(2, 2)    # Create a tensor filled with ones of size 2x2\n",
    "random = torch.randn(3, 3) # Create a tensor filled with random values of size 3x3\n",
    "\n",
    "print(\n",
    "    f\"Array of zeroes:\\n {zeros}\\n\",\n",
    "    f\"Array of ones:\\n {ones}\\n\",\n",
    "    f\"Array of random values:\\n {random}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because one of the most important features of PyTorch is the ability to speed computations on GPUs, the library comes with methods to see whether we're currently using the CPU or accelerated computations on GPU. The `device` attribute shows us the current device in use by the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "else:\n",
    "    print(f\"cuda is not available, using {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing mathematical operations on tensors\n",
    "\n",
    "The most important aspect of tensors is their use for the mathematical operations that power deep learning in neural networks. Many basic matrix operations are easy to perform in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "sum_ab = a + b\n",
    "diff_ab = a - b\n",
    "mul_ab = a * b\n",
    "div_ab = a / b           \n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Element-wise addition:\\n {sum_ab}\\n\",\n",
    "    f\"Element-wise subtraction:\\n {diff_ab}\\n\",\n",
    "    f\"Element-wise multiplication:\\n {mul_ab}\\n\",\n",
    "    f\"Element-wise division:\\n {div_ab}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the most important mathematical operations in neural networks involve matrix multiplication. However, there are multiple ways to multipy tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_ab = a.dot(b)\n",
    "mul_ab = a * b\n",
    "\n",
    "print(\n",
    "  f\"Dot product of A and B:\\n {dot_ab}\\n\",\n",
    "  f\"Element-wise multiplication:\\n {mul_ab}\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful properties of PyTorch tensors\n",
    "\n",
    "While the mathematical properties above are useful when doing lower-level deep learning operations, there are also many other standard operations that help use with everyday usage. This is by no means an exhaustive list, but a small sample of the suite of operations supported out-ofâ€“the-box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once created, tensors can be indexed and sliced just like lists and other array objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first element\n",
    "tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first two elements \n",
    "tensor[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last element\n",
    "tensor[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `torch.Tensor` object has a number of other useful methods for manipulating the tensor itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.Tensor(\n",
    "    [1,2,3]\n",
    ")\n",
    "\n",
    "# reverse the tensor\n",
    "print(tensor.flip(dims=(-1,)))\n",
    "\n",
    "# reshape the tensor\n",
    "print(tensor.reshape(3,1))\n",
    "\n",
    "# get the largest value\n",
    "print(tensor.max())\n",
    "\n",
    "# get the smallest value\n",
    "print(tensor.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some operations are only supported on tensors of >1 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.Tensor(\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [4,5,6],\n",
    "        [7,8,9]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# flatten the tensor\n",
    "print(tensor.flatten())\n",
    "\n",
    "# tranpose the tensor\n",
    "print(tensor.mT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "That's all for now! Again - the purpose here is just to get you as familiar working with the `torch.Tensor` object as you might be with Python lists. Next time, we'll talk about one of the most important aspects of PyTorch tensors that allows them to learn: gradients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
